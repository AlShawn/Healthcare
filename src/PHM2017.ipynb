{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-the-PHM2017-dataset\" data-toc-modified-id=\"Load-the-PHM2017-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load the PHM2017 dataset</a></span></li><li><span><a href=\"#Experiment-Settting-Explanation\" data-toc-modified-id=\"Experiment-Settting-Explanation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Experiment Settting Explanation</a></span></li><li><span><a href=\"#Train-baseline-model-of-stroke-dataset\" data-toc-modified-id=\"Train-baseline-model-of-stroke-dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train baseline model of stroke dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#split-dataset-by-symptom\" data-toc-modified-id=\"split-dataset-by-symptom-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>split dataset by symptom</a></span></li><li><span><a href=\"#tf-idf-and-LR\" data-toc-modified-id=\"tf-idf-and-LR-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>tf-idf and LR</a></span></li><li><span><a href=\"#word-embedding-and-LR\" data-toc-modified-id=\"word-embedding-and-LR-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>word embedding and LR</a></span></li><li><span><a href=\"#word-embedding-and-MLP\" data-toc-modified-id=\"word-embedding-and-MLP-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>word embedding and MLP</a></span></li><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>LSTM</a></span></li><li><span><a href=\"#overall-baseline\" data-toc-modified-id=\"overall-baseline-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>overall baseline</a></span></li></ul></li><li><span><a href=\"#Add-additional-features\" data-toc-modified-id=\"Add-additional-features-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Add additional features</a></span><ul class=\"toc-item\"><li><span><a href=\"#keyword-extraction-and-conceptualization\" data-toc-modified-id=\"keyword-extraction-and-conceptualization-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>keyword extraction and conceptualization</a></span></li></ul></li><li><span><a href=\"#Some-thoughts:\" data-toc-modified-id=\"Some-thoughts:-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Some thoughts:</a></span></li><li><span><a href=\"#Baseline-results-for-all-classes\" data-toc-modified-id=\"Baseline-results-for-all-classes-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Baseline results for all classes</a></span><ul class=\"toc-item\"><li><span><a href=\"#split-all-datasets\" data-toc-modified-id=\"split-all-datasets-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>split all datasets</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = None #show all cols\n",
    "pd.options.display.max_colwidth = -1 #show complete value in each cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the PHM2017 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../clean_data/PHM2017/PHM2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5288, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>symptom</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>811645757732352004</td>\n",
       "      <td>my left arm is numb I'm about to have a heart attack and die this is it boys, sci till I die</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>811646344314101760</td>\n",
       "      <td>I think I'm having a heart attack \\r\\r\\nMy chest hurts</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>811647202258984961</td>\n",
       "      <td>Cause lord knows I was boutta have a heart attack</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>811652281062068224</td>\n",
       "      <td>2 years ago I survived a heart attack through God's provision and Dr. Zidar's awesome skills. My annual visit is a spiritual experience!</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>811652415875416068</td>\n",
       "      <td>i'm gonna have a heart attack at like 25</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>811656615002783744</td>\n",
       "      <td>I love Five Guys too, they'll probably give me a heart attack one day</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>811658251200774144</td>\n",
       "      <td>JESuS fucking cHRIST I did not need a heart attack today I really didn't.</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>811660394947313664</td>\n",
       "      <td>- would have just passed out from a heart attack or something of the sort. \\r\\r\\n\\r\\r\\n\"He could have at least told me...\" He mumbled, -</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>811661175989604356</td>\n",
       "      <td>Ahah! I searched my tweets, couldn't find it!!! Alzheimer's is a dreadful thing! I SAID ALZHEIMERS IS A DREADFUL THING!</td>\n",
       "      <td>alzheimer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>811664602433921024</td>\n",
       "      <td>I JUST HAD A HEART ATTACK OVER NOTHING</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>811665510874030081</td>\n",
       "      <td>An instant heart attack. I can't even move</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>811666765507887104</td>\n",
       "      <td>just come back after 6months off due to heart attack, but only on light duties so can't ride the truck</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>811666861838372864</td>\n",
       "      <td>Just not feeling Christmas this year. Still have post heart attack depression, which is normal.</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>811672320695791616</td>\n",
       "      <td>hey i just met you, and this is crazy, i have alzheimer, hey i just met you</td>\n",
       "      <td>alzheimer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>811675495582547968</td>\n",
       "      <td>Those pains in my chest - maybe a heart attack? Who knows? Well, a doctor would, but I've already used up this year's healthcare so....</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>811675534295855104</td>\n",
       "      <td>I think I just had a heart attack</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>811676444547911681</td>\n",
       "      <td>googles: is this what it feels like to have a heart attack</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>811678716061306880</td>\n",
       "      <td>I SCREAMED AND GASPED SO LOUD I HAD A HEART ATTACK</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>811679225220628480</td>\n",
       "      <td>When you consume just coffee and have chest pain and think \"am I going to have a heart attack?\" But still continue having coffee</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>811686551574941698</td>\n",
       "      <td>i once thought i was having a heart attack when i was little cause i had chest pains i was so worried</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>811691348965343232</td>\n",
       "      <td>I thought you'd take credit for inventing Christmas lights. Herr Edwards ironically died in an electrical accident. Gave you heart attack?</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>811692386724302849</td>\n",
       "      <td>I just had a heart attack</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>811693535242125313</td>\n",
       "      <td>\"I'm about to have s heart attack\"\\r\\r\\n@aracelih2002</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>811699576054943745</td>\n",
       "      <td>told my mum i think i'm having a heart attack and she said \"play more football\"  bruhhhh?? #asianparents</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>811699625677635584</td>\n",
       "      <td>Time for my yearly skin cancer checkup.</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>811701308637978624</td>\n",
       "      <td>20 yrs ago, I had terminal #Cancer with no cure in sight. Read about my miracle! http://ln.is/Ybodg  by #IronmanMann via @c0nvey</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>811701722087309312</td>\n",
       "      <td>I'm almost 6 yrs #CancerFree. 2016's been the best and the worst. \"I don't live in the past but it's nice to visit\" http://bit.ly/2hR8lnT</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>811702035116675072</td>\n",
       "      <td>Stressing gonna fuck around and give me a heart attack</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>811702497119113216</td>\n",
       "      <td>Cancer free still and my heart is doing okay!</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>811703048468918272</td>\n",
       "      <td>@BrannenKris @VP I survived cancer, younger brother lost battle. Sis had breast cancer, survived. Older bro just diagnosed lung cancer.</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>905540488249438209</td>\n",
       "      <td>I didn't know I could cure my depression by fucking reading flat Stanley</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>905540649264574464</td>\n",
       "      <td>So my heart has been feeling weird for some time now. Maybe a heart attack soon?\\r\\r\\nI won't hold my breath but I'd welcome it.</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>905540766205927425</td>\n",
       "      <td>i cant #readabookaday i have horrible adhd, dyslexia, and crippling depression and anxiety</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>905541120712511488</td>\n",
       "      <td>Sup my peeps Im going offline for a while Vid w still come jst not as much Ive been developing depression I jst need 2 reconnect w the world</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>905541303710212096</td>\n",
       "      <td>I'm a huge fan of the Dolan twins, I sing, I live my friends and family, but I suffer from depression</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>905541406038654977</td>\n",
       "      <td>i've slept about 4 times today and it's only about to be 5.. depression is hitting me hard today</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>905542215354785792</td>\n",
       "      <td>Depression is killing me</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>905542229300826112</td>\n",
       "      <td>Working with depression</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>905542242617708545</td>\n",
       "      <td>Going through first episode of depression. I really would love some support.</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>905542263849279489</td>\n",
       "      <td>I wish my depression would just stop for like five minutes lol</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>905542309227274240</td>\n",
       "      <td>my depression is coming back and the only thing i wanna do is break down and cry</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>905542332711403521</td>\n",
       "      <td>I could write essay upon essay \\r\\r\\nabout how depression has robbed me \\r\\r\\nof the will to write\\r\\r\\n#LossLit</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>905542647602974722</td>\n",
       "      <td>Just went to my Oncology appointment at the Hospital and they said they found a small tumor next to my heart!!! Praying that it's not cancer</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>905542650220171264</td>\n",
       "      <td>Crawled far enough out of my depression to play warframe.</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>905542738623438848</td>\n",
       "      <td>Find me wrapped up in my covers with post-NCLEX depression.....</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>905542872656748544</td>\n",
       "      <td>I have depression so when I feel like killing myself, fucking deal with it.</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>905542957075456000</td>\n",
       "      <td>That just because I \"seem fine\" at work or around family doesn't mean I'm not suffering. Depression isn't something I can just suck up.</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>905543340233543680</td>\n",
       "      <td>I wonder about many things... Things that trigger my depression... The causes and reasons... I wonder when I'll finally stop wondering...</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>905543431635816449</td>\n",
       "      <td>I listen to music to deal with the depression everyday</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>905543514892771332</td>\n",
       "      <td>I beat #cancer and now I loath it, and I don't even wanna read the word, much less talk about it. I just wanna forget it. #Anger</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>905543542642278400</td>\n",
       "      <td>I HATE when people pity me and others for our depression or treat me like a child because of it. All I want is to be treated like a normal …</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>905543665900285952</td>\n",
       "      <td>Depression makes it near impossible to do such trivial things. I am DETERMINED to leave the house tomorrow. And wash my hair.</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>905543736318406656</td>\n",
       "      <td>Dear Cancer-You suck! You sucked the life out of me. I want my life back. http://ow.ly/8Xa430eXX5r  #cancersucks #dearcancer</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>905543964845060100</td>\n",
       "      <td>Not sure how to respond to people recommending teas &amp; diets to fight my cancer. Like thanks, but I'm going to go with what my drs say.</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023</th>\n",
       "      <td>905543965407137793</td>\n",
       "      <td>#cancer took my life away even tho I am still alive: no one can understand unless they have traveled this path.</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>905544189005492224</td>\n",
       "      <td>I dealt w/ the not cool during/after my fight w/ depression and it restored me embracing my crazy, strong foundation of joy.. YOU can too!</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>905544277274570753</td>\n",
       "      <td>I had to deny having twitter at work 2day bc Im not ready 4 my new colleagues to discover Im a mild sex addict w depression and daddy issues</td>\n",
       "      <td>depression</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>905554207301873665</td>\n",
       "      <td>I believe that I'm battling Cancer for others to witness GOD's work.Strong,powerful,and positive to continue my initial journey.#wincancer</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>905621574413414400</td>\n",
       "      <td>A3 Three years ago when I was diagnosed with cancer, it gave me a learning experience I wouldn't have had otherwise. #weirded</td>\n",
       "      <td>cancer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>905801405117722626</td>\n",
       "      <td>Just realized I haven't had the weird-lip-twitch-that's-probably-Parkinson's for months. Watch it come back now.</td>\n",
       "      <td>parkinson</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "12    811645757732352004   \n",
       "19    811646344314101760   \n",
       "28    811647202258984961   \n",
       "67    811652281062068224   \n",
       "69    811652415875416068   \n",
       "93    811656615002783744   \n",
       "112   811658251200774144   \n",
       "131   811660394947313664   \n",
       "140   811661175989604356   \n",
       "198   811664602433921024   \n",
       "207   811665510874030081   \n",
       "220   811666765507887104   \n",
       "222   811666861838372864   \n",
       "306   811672320695791616   \n",
       "352   811675495582547968   \n",
       "354   811675534295855104   \n",
       "376   811676444547911681   \n",
       "420   811678716061306880   \n",
       "429   811679225220628480   \n",
       "532   811686551574941698   \n",
       "585   811691348965343232   \n",
       "590   811692386724302849   \n",
       "604   811693535242125313   \n",
       "679   811699576054943745   \n",
       "684   811699625677635584   \n",
       "778   811701308637978624   \n",
       "800   811701722087309312   \n",
       "811   811702035116675072   \n",
       "833   811702497119113216   \n",
       "873   811703048468918272   \n",
       "...                  ...   \n",
       "4858  905540488249438209   \n",
       "4863  905540649264574464   \n",
       "4867  905540766205927425   \n",
       "4878  905541120712511488   \n",
       "4886  905541303710212096   \n",
       "4890  905541406038654977   \n",
       "4917  905542215354785792   \n",
       "4919  905542229300826112   \n",
       "4922  905542242617708545   \n",
       "4923  905542263849279489   \n",
       "4927  905542309227274240   \n",
       "4929  905542332711403521   \n",
       "4949  905542647602974722   \n",
       "4950  905542650220171264   \n",
       "4956  905542738623438848   \n",
       "4961  905542872656748544   \n",
       "4964  905542957075456000   \n",
       "4978  905543340233543680   \n",
       "4982  905543431635816449   \n",
       "4985  905543514892771332   \n",
       "4987  905543542642278400   \n",
       "4995  905543665900285952   \n",
       "5001  905543736318406656   \n",
       "5022  905543964845060100   \n",
       "5023  905543965407137793   \n",
       "5036  905544189005492224   \n",
       "5045  905544277274570753   \n",
       "5053  905554207301873665   \n",
       "5191  905621574413414400   \n",
       "5247  905801405117722626   \n",
       "\n",
       "                                                                                                                                             tweet  \\\n",
       "12    my left arm is numb I'm about to have a heart attack and die this is it boys, sci till I die                                                   \n",
       "19    I think I'm having a heart attack \\r\\r\\nMy chest hurts                                                                                         \n",
       "28    Cause lord knows I was boutta have a heart attack                                                                                              \n",
       "67    2 years ago I survived a heart attack through God's provision and Dr. Zidar's awesome skills. My annual visit is a spiritual experience!       \n",
       "69    i'm gonna have a heart attack at like 25                                                                                                       \n",
       "93    I love Five Guys too, they'll probably give me a heart attack one day                                                                          \n",
       "112   JESuS fucking cHRIST I did not need a heart attack today I really didn't.                                                                      \n",
       "131   - would have just passed out from a heart attack or something of the sort. \\r\\r\\n\\r\\r\\n\"He could have at least told me...\" He mumbled, -       \n",
       "140   Ahah! I searched my tweets, couldn't find it!!! Alzheimer's is a dreadful thing! I SAID ALZHEIMERS IS A DREADFUL THING!                        \n",
       "198   I JUST HAD A HEART ATTACK OVER NOTHING                                                                                                         \n",
       "207   An instant heart attack. I can't even move                                                                                                     \n",
       "220   just come back after 6months off due to heart attack, but only on light duties so can't ride the truck                                         \n",
       "222   Just not feeling Christmas this year. Still have post heart attack depression, which is normal.                                                \n",
       "306   hey i just met you, and this is crazy, i have alzheimer, hey i just met you                                                                    \n",
       "352   Those pains in my chest - maybe a heart attack? Who knows? Well, a doctor would, but I've already used up this year's healthcare so....        \n",
       "354   I think I just had a heart attack                                                                                                              \n",
       "376   googles: is this what it feels like to have a heart attack                                                                                     \n",
       "420   I SCREAMED AND GASPED SO LOUD I HAD A HEART ATTACK                                                                                             \n",
       "429   When you consume just coffee and have chest pain and think \"am I going to have a heart attack?\" But still continue having coffee               \n",
       "532   i once thought i was having a heart attack when i was little cause i had chest pains i was so worried                                          \n",
       "585   I thought you'd take credit for inventing Christmas lights. Herr Edwards ironically died in an electrical accident. Gave you heart attack?     \n",
       "590   I just had a heart attack                                                                                                                      \n",
       "604   \"I'm about to have s heart attack\"\\r\\r\\n@aracelih2002                                                                                          \n",
       "679   told my mum i think i'm having a heart attack and she said \"play more football\"  bruhhhh?? #asianparents                                       \n",
       "684   Time for my yearly skin cancer checkup.                                                                                                        \n",
       "778   20 yrs ago, I had terminal #Cancer with no cure in sight. Read about my miracle! http://ln.is/Ybodg  by #IronmanMann via @c0nvey               \n",
       "800   I'm almost 6 yrs #CancerFree. 2016's been the best and the worst. \"I don't live in the past but it's nice to visit\" http://bit.ly/2hR8lnT      \n",
       "811   Stressing gonna fuck around and give me a heart attack                                                                                         \n",
       "833   Cancer free still and my heart is doing okay!                                                                                                  \n",
       "873   @BrannenKris @VP I survived cancer, younger brother lost battle. Sis had breast cancer, survived. Older bro just diagnosed lung cancer.        \n",
       "...                                                                                                                                       ...        \n",
       "4858  I didn't know I could cure my depression by fucking reading flat Stanley                                                                       \n",
       "4863  So my heart has been feeling weird for some time now. Maybe a heart attack soon?\\r\\r\\nI won't hold my breath but I'd welcome it.               \n",
       "4867  i cant #readabookaday i have horrible adhd, dyslexia, and crippling depression and anxiety                                                     \n",
       "4878  Sup my peeps Im going offline for a while Vid w still come jst not as much Ive been developing depression I jst need 2 reconnect w the world   \n",
       "4886  I'm a huge fan of the Dolan twins, I sing, I live my friends and family, but I suffer from depression                                          \n",
       "4890  i've slept about 4 times today and it's only about to be 5.. depression is hitting me hard today                                               \n",
       "4917  Depression is killing me                                                                                                                       \n",
       "4919  Working with depression                                                                                                                        \n",
       "4922  Going through first episode of depression. I really would love some support.                                                                   \n",
       "4923  I wish my depression would just stop for like five minutes lol                                                                                 \n",
       "4927  my depression is coming back and the only thing i wanna do is break down and cry                                                               \n",
       "4929  I could write essay upon essay \\r\\r\\nabout how depression has robbed me \\r\\r\\nof the will to write\\r\\r\\n#LossLit                               \n",
       "4949  Just went to my Oncology appointment at the Hospital and they said they found a small tumor next to my heart!!! Praying that it's not cancer   \n",
       "4950  Crawled far enough out of my depression to play warframe.                                                                                      \n",
       "4956  Find me wrapped up in my covers with post-NCLEX depression.....                                                                                \n",
       "4961  I have depression so when I feel like killing myself, fucking deal with it.                                                                    \n",
       "4964  That just because I \"seem fine\" at work or around family doesn't mean I'm not suffering. Depression isn't something I can just suck up.        \n",
       "4978  I wonder about many things... Things that trigger my depression... The causes and reasons... I wonder when I'll finally stop wondering...      \n",
       "4982  I listen to music to deal with the depression everyday                                                                                         \n",
       "4985  I beat #cancer and now I loath it, and I don't even wanna read the word, much less talk about it. I just wanna forget it. #Anger               \n",
       "4987  I HATE when people pity me and others for our depression or treat me like a child because of it. All I want is to be treated like a normal …   \n",
       "4995  Depression makes it near impossible to do such trivial things. I am DETERMINED to leave the house tomorrow. And wash my hair.                  \n",
       "5001  Dear Cancer-You suck! You sucked the life out of me. I want my life back. http://ow.ly/8Xa430eXX5r  #cancersucks #dearcancer                   \n",
       "5022  Not sure how to respond to people recommending teas & diets to fight my cancer. Like thanks, but I'm going to go with what my drs say.         \n",
       "5023  #cancer took my life away even tho I am still alive: no one can understand unless they have traveled this path.                                \n",
       "5036  I dealt w/ the not cool during/after my fight w/ depression and it restored me embracing my crazy, strong foundation of joy.. YOU can too!     \n",
       "5045  I had to deny having twitter at work 2day bc Im not ready 4 my new colleagues to discover Im a mild sex addict w depression and daddy issues   \n",
       "5053  I believe that I'm battling Cancer for others to witness GOD's work.Strong,powerful,and positive to continue my initial journey.#wincancer     \n",
       "5191  A3 Three years ago when I was diagnosed with cancer, it gave me a learning experience I wouldn't have had otherwise. #weirded                  \n",
       "5247  Just realized I haven't had the weird-lip-twitch-that's-probably-Parkinson's for months. Watch it come back now.                               \n",
       "\n",
       "           symptom  label  \n",
       "12    heart attack  3      \n",
       "19    heart attack  3      \n",
       "28    heart attack  3      \n",
       "67    heart attack  3      \n",
       "69    heart attack  3      \n",
       "93    heart attack  3      \n",
       "112   heart attack  3      \n",
       "131   heart attack  3      \n",
       "140   alzheimer     3      \n",
       "198   heart attack  3      \n",
       "207   heart attack  3      \n",
       "220   heart attack  3      \n",
       "222   heart attack  3      \n",
       "306   alzheimer     3      \n",
       "352   heart attack  3      \n",
       "354   heart attack  3      \n",
       "376   heart attack  3      \n",
       "420   heart attack  3      \n",
       "429   heart attack  3      \n",
       "532   heart attack  3      \n",
       "585   heart attack  3      \n",
       "590   heart attack  3      \n",
       "604   heart attack  3      \n",
       "679   heart attack  3      \n",
       "684   cancer        3      \n",
       "778   cancer        3      \n",
       "800   cancer        3      \n",
       "811   heart attack  3      \n",
       "833   cancer        3      \n",
       "873   cancer        3      \n",
       "...      ...       ..      \n",
       "4858  depression    3      \n",
       "4863  heart attack  3      \n",
       "4867  depression    3      \n",
       "4878  depression    3      \n",
       "4886  depression    3      \n",
       "4890  depression    3      \n",
       "4917  depression    3      \n",
       "4919  depression    3      \n",
       "4922  depression    3      \n",
       "4923  depression    3      \n",
       "4927  depression    3      \n",
       "4929  depression    3      \n",
       "4949  cancer        3      \n",
       "4950  depression    3      \n",
       "4956  depression    3      \n",
       "4961  depression    3      \n",
       "4964  depression    3      \n",
       "4978  depression    3      \n",
       "4982  depression    3      \n",
       "4985  cancer        3      \n",
       "4987  depression    3      \n",
       "4995  depression    3      \n",
       "5001  cancer        3      \n",
       "5022  cancer        3      \n",
       "5023  cancer        3      \n",
       "5036  depression    3      \n",
       "5045  depression    3      \n",
       "5053  cancer        3      \n",
       "5191  cancer        3      \n",
       "5247  parkinson     3      \n",
       "\n",
       "[396 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()\n",
    "df.loc[df['label']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symptom\n",
      "alzheimer       1045\n",
      "cancer           911\n",
      "depression       836\n",
      "heart attack     813\n",
      "parkinson        793\n",
      "stroke           890\n",
      "Name: id, dtype: int64\n",
      "\n",
      "alzheimer\n",
      " [0.01722488 0.815311   0.16076555 0.00669856]\n",
      "\n",
      "cancer\n",
      " [0.13501647 0.66081229 0.17453348 0.02963776]\n",
      "\n",
      "depression\n",
      " [0.1208134  0.49521531 0.03349282 0.35047847]\n",
      "\n",
      "heart attack\n",
      " [0.67527675 0.18819188 0.09717097 0.03936039]\n",
      "\n",
      "parkinson\n",
      " [0.23076923 0.66834805 0.08322825 0.01765448]\n",
      "\n",
      "stroke\n",
      " [0.55168539 0.29775281 0.1247191  0.0258427 ]\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['symptom']).count()['id'])\n",
    "print('\\nalzheimer\\n',df.groupby(['symptom','label']).count().loc['alzheimer']['id'].apply(lambda x:x/1045).values)\n",
    "print('\\ncancer\\n',df.groupby(['symptom','label']).count().loc['cancer']['id'].apply(lambda x:x/911).values)\n",
    "print('\\ndepression\\n',df.groupby(['symptom','label']).count().loc['depression']['id'].apply(lambda x:x/836).values)\n",
    "print('\\nheart attack\\n',df.groupby(['symptom','label']).count().loc['heart attack']['id'].apply(lambda x:x/813).values)\n",
    "print('\\nparkinson\\n',df.groupby(['symptom','label']).count().loc['parkinson']['id'].apply(lambda x:x/793).values)\n",
    "print('\\nstroke\\n',df.groupby(['symptom','label']).count().loc['stroke']['id'].apply(lambda x:x/890).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to original dataset each are less about 200-300 samples per symptom ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"symptom\", hue=\"label\", data=df).figure.savefig(\"output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Explanation:  \n",
    "0: non-health  \n",
    "1: awareness  \n",
    "2: other-mention  \n",
    "3: self-mention.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each category of symptom, they suffer from a huge data imbanlanced problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Settting Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the original experiments, *self-mention* and *other-mention* labels are taken as **positive class**; and *awareness* and *non-health* labels are taken as **negative class**.  \n",
    "\n",
    "- Due to the data imbanlance problem. They report the result using Precision,Recall,F1 score of the **minority class(positive class)** to give the evaluation.\n",
    "\n",
    "- Standard 10 fold Cross-Validation within each topic of PHM2017 dataset. The results reported are the averages over the test folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train baseline model of stroke dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset by symptom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we take the stroke dataset to do the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['symptom']=='alzheimer'].shape\n",
    "df[df['symptom']=='cancer'].shape\n",
    "df[df['symptom']=='depression'].shape\n",
    "df[df['symptom']=='heart attack'].shape\n",
    "df[df['symptom']=='parkinson'].shape\n",
    "df[df['symptom']=='stroke'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stroke=df[df['symptom']=='stroke'][['tweet','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>Bad news... I need prayers or good thoughts. W...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>Alex would move his left hand to gently stroke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>Q: Have you heard that George Michael was foun...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>That's a good girl. Stroke it baby. -Smirks an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>At the third stroke the time in the UK will be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>\"Remember that sometimes not getting what you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>This Updated Pegboard Game Helps Stroke Victim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>Having at least one \"lazy day\" per week can re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  label\n",
       "2459  Bad news... I need prayers or good thoughts. W...      2\n",
       "2465  Alex would move his left hand to gently stroke...      0\n",
       "2501  Q: Have you heard that George Michael was foun...      2\n",
       "2755  That's a good girl. Stroke it baby. -Smirks an...      0\n",
       "3589  At the third stroke the time in the UK will be...      0\n",
       "3590  \"Remember that sometimes not getting what you ...      0\n",
       "3795  This Updated Pegboard Game Helps Stroke Victim...      1\n",
       "4649  Having at least one \"lazy day\" per week can re...      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stroke[df_stroke.tweet.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  tf-idf and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..., penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegression(random_state=0,max_iter=500,solver='lbfgs',\n",
    "                            multi_class='multinomial')),\n",
    "])\n",
    "\n",
    "text_clf.fit(df_stroke.tweet.values, df_stroke.label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.10073256, 0.10272551, 0.11170197, 0.1067152 , 1.54386878]),\n",
       " 'score_time': array([0.02792358, 0.01795268, 0.01695371, 0.01695466, 0.02692723]),\n",
       " 'test_precision_macro': array([0.59166667, 0.49883376, 0.58772265, 0.59251208, 0.59620536]),\n",
       " 'train_precision_macro': array([0.70043087, 0.70166171, 0.70011404, 0.7021234 , 0.70335369]),\n",
       " 'test_recall_macro': array([0.41941358, 0.41625389, 0.4503448 , 0.46155967, 0.42459394]),\n",
       " 'train_recall_macro': array([0.6136473 , 0.61042479, 0.61042479, 0.61821603, 0.61885175]),\n",
       " 'test_f1_macro': array([0.44036427, 0.40464494, 0.46352478, 0.47416877, 0.44424214]),\n",
       " 'train_f1_macro': array([0.64028094, 0.63770495, 0.63709903, 0.64504073, 0.64540262])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "predicted = text_clf.predict(df_stroke.tweet.values)\n",
    "scoring = ['precision_macro', 'recall_macro','f1_macro']\n",
    "scores = cross_validate(text_clf, df_stroke.tweet.values, df_stroke.label, \n",
    "                         scoring=scoring,\n",
    "                         cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf+LR average f1 on test set: 0.44538898\n"
     ]
    }
   ],
   "source": [
    "print('tfidf+LR average f1 on test set:',np.mean(np.array([0.44036427, 0.40464494, 0.46352478, 0.47416877, 0.44424214])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(890,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.91       491\n",
      "           1       0.97      0.89      0.93       265\n",
      "           2       1.00      0.62      0.77       111\n",
      "           3       0.00      0.00      0.00        23\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       890\n",
      "   macro avg       0.70      0.63      0.65       890\n",
      "weighted avg       0.88      0.89      0.88       890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(predicted.shape)\n",
    "print(metrics.classification_report(df[df['symptom']=='stroke'].label, predicted))\n",
    "#      target_names=df.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word embedding and LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove embedding and average as sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=300\n",
    "# glove embedding \n",
    "# use average as sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "df_stroke\n",
    "tk = TweetTokenizer()\n",
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r',encoding='utf-8')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "embedding_dic=loadGloveModel('D:/Datasets/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[]\n",
    "for t in df_stroke.tweet.tolist():\n",
    "    dataset.append(tk.tokenize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22], dtype=int64),)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_emb=np.zeros((len(dataset),EMBEDDING_DIM))\n",
    "for i in range(len(dataset)):\n",
    "    each_emb=np.zeros((len(dataset[i]),EMBEDDING_DIM))\n",
    "    for j,w in enumerate(dataset[i]):\n",
    "        if(w in embedding_dic):\n",
    "            each_emb[j]=embedding_dic[w]\n",
    "#             break\n",
    "    data_emb[i]=np.mean(each_emb, axis=0)        \n",
    "        \n",
    "#     nonzero_inds=np.nonzero(dataset[i].flatten())\n",
    "#     review_emb=embedding_matrix[nonzero_inds]\n",
    "#     data_emb[i]=np.mean(review_emb, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.06033444, 0.05684853, 0.05086398, 0.05186009, 0.05788112]),\n",
       " 'score_time': array([0.00199437, 0.00199628, 0.00199437, 0.00199556, 0.00299454]),\n",
       " 'test_precision_macro': array([0.55944684, 0.55011261, 0.63769871, 0.53176218, 0.57835334]),\n",
       " 'train_precision_macro': array([0.89831149, 0.88164612, 0.89003318, 0.89320655, 0.87574066]),\n",
       " 'test_recall_macro': array([0.51775134, 0.5195374 , 0.5440412 , 0.48304425, 0.57511289]),\n",
       " 'train_recall_macro': array([0.6070613 , 0.62480363, 0.60968706, 0.63669937, 0.60015559]),\n",
       " 'test_f1_macro': array([0.53176464, 0.52898339, 0.57127736, 0.49753122, 0.5752635 ]),\n",
       " 'train_f1_macro': array([0.63939964, 0.66057232, 0.65266098, 0.68268774, 0.6399105 ])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                          multi_class='multinomial')\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro','f1_macro']\n",
    "scores = cross_validate(clf, data_emb, df_stroke.label, \n",
    "#                         print evaluation metric for each class\n",
    "#                          scoring=make_scorer(classification_report_with_accuracy_score),\n",
    "                         scoring=scoring,\n",
    "                         cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe+LR average f1 on test set: 0.540964022\n"
     ]
    }
   ],
   "source": [
    "print('GloVe+LR average f1 on test set:',np.mean(np.array([0.53176464, 0.52898339, 0.57127736, 0.49753122, 0.5752635 ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word embedding and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.56659627, 2.77657127, 3.20047545, 2.71680737, 3.25139666]),\n",
       " 'score_time': array([0.00598216, 0.00498772, 0.00498581, 0.00598335, 0.00598288]),\n",
       " 'test_precision_macro': array([0.67597188, 0.51856777, 0.57239541, 0.53682627, 0.64107251]),\n",
       " 'train_precision_macro': array([0.99810127, 0.99873418, 0.99810606, 0.99936548, 0.99810606]),\n",
       " 'test_recall_macro': array([0.68778722, 0.5050014 , 0.57101726, 0.55517293, 0.69409196]),\n",
       " 'train_recall_macro': array([0.9948006 , 0.99764151, 0.99483252, 0.99719101, 0.99483252]),\n",
       " 'test_f1_macro': array([0.67632275, 0.5103583 , 0.57038027, 0.54460784, 0.66288015]),\n",
       " 'train_f1_macro': array([0.99643361, 0.99818065, 0.99645217, 0.99826991, 0.99645217])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "hidden_neurons=256\n",
    "    \n",
    "classifier = MLPClassifier(hidden_layer_sizes=(hidden_neurons,hidden_neurons), max_iter=1000, alpha=0.001,\n",
    "                     solver='adam', verbose=0,  random_state=0)\n",
    "\n",
    "print(\"start training..\")\n",
    "# classifier.fit(X_train_emb,y_train)\n",
    "scoring = ['precision_macro', 'recall_macro','f1_macro']\n",
    "scores = cross_validate(classifier, data_emb, df_stroke.label, \n",
    "#                         print evaluation metric for each class\n",
    "#                          scoring=make_scorer(classification_report_with_accuracy_score),\n",
    "                         scoring=scoring,\n",
    "                         cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe+MLP average f1 on test set: 0.592909862\n"
     ]
    }
   ],
   "source": [
    "print('GloVe+MLP average f1 on test set:',(0.67632275+0.5103583+0.57038027+0.54460784+0.66288015)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# Others\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#load glove into embeddings_index\n",
    "embeddings_index = dict()\n",
    "f = open('D:/Datasets/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embeddings_index=embedding_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overall baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Word Vector | ML Model   |Average F1\n",
    "|------|------|------|\n",
    "| tf-idf | LR   | 0.44538898 |\n",
    "|   GloVe  | LR| 0.540964022|\n",
    "|   GloVe  | MLP| 0.592909862|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keyword extraction and conceptualization\n",
    "\n",
    "- use **tf-idf weight** extract the keywords of each tweet\n",
    "- and enhanced by **conceptulization knowledge** of the keywords embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "# edit the number_of_concepts to get top_k concepts\n",
    "number_of_concepts=1\n",
    "\n",
    "def get_concepts(keyword):\n",
    "#     keyword='string'\n",
    "    keyword=keyword.replace(' ','%20')\n",
    "    url = 'https://concept.research.microsoft.com/api/Concept/ScoreByProb?instance='+keyword+'&topK=10'\n",
    "    try:\n",
    "        f = urllib.request.urlopen(url)\n",
    "        concept_dic=eval(f.read().decode('utf-8'))\n",
    "        top_concept=list(concept_dic.keys())\n",
    "#         print(list(concept_dic.keys())[:number_of_concepts])\n",
    "        return top_concept[:number_of_concepts]\n",
    "    except:\n",
    "        print('error')\n",
    "        return []\n",
    "\n",
    "get_concepts('microsoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   ['shift operation', 'title', 'word']\n",
      "1   ['factor']\n",
      "2   ['film', 'time', 'featuring big breasted beauty']\n",
      "3   ['problem']\n",
      "4   ['fastener', 'quality']\n",
      "5   ['holiday', 'animal']\n",
      "6   ['information', 'word']\n",
      "7   ['item', 'device specific information', 'information']\n",
      "8   ['family', 'predator', 'information']\n",
      "9   ['song', 'state', 'poor discharge']\n",
      "10   ['product', 'album', 'meat']\n",
      "11   ['great civilization']\n",
      "12   ['item', 'animal', 'information']\n",
      "13   ['name', 'mode']\n",
      "14   ['word', 'scholar', 'symptom']\n",
      "error\n",
      "15   ['word', 'bayern target']\n",
      "16   ['chaperone', 'pollutant']\n",
      "17   ['value', 'word']\n",
      "18   ['city', 'area', 'local authority']\n",
      "19   ['city', 'livebearer']\n",
      "20   ['surface', 'work', 'nids']\n",
      "21   ['string', 'popular audio format', 'small g protein']\n",
      "22   ['ethnic group', 'category']\n",
      "23   ['word', 'hairstyle']\n",
      "24   ['song', 'catchphrase', 'item']\n",
      "25   ['work', 'singular article']\n",
      "26   []\n",
      "27   ['physiological parameter', 'genre']\n",
      "28   ['command', 'interface name']\n",
      "29   ['self reported category', 'word']\n",
      "30   ['neckline', 'area']\n",
      "31   ['author', 'right winger', 'information']\n",
      "32   ['factor', 'part']\n",
      "33   ['number', 'word']\n",
      "34   ['item', 'sensation', 'heartfelt track']\n",
      "35   ['film', 'personal line']\n",
      "36   ['emotion', 'area']\n",
      "37   ['risk factor', 'measure', 'word']\n",
      "38   ['lifestyle change', 'sound']\n",
      "39   []\n",
      "40   ['product']\n",
      "41   ['word', 'team', 'command']\n",
      "42   ['role', 'endurance athlete']\n",
      "43   ['symbolic gesture', 'part store', 'stakeholder']\n",
      "44   ['person']\n",
      "45   ['application', 'factor', 'activity']\n",
      "46   ['hurricane', 'researcher', 'song']\n",
      "47   ['sensation', 'illegal drug', 'emotion']\n",
      "48   ['topic', 'condition', 'word']\n",
      "49   ['issue', 'industry']\n",
      "50   ['bird', 'musical', 'word']\n",
      "51   ['legal document', 'artery']\n",
      "52   ['artery', 'factor']\n",
      "53   ['information']\n",
      "54   ['holiday', 'family member']\n",
      "55   ['mean of traffic control', 'expense']\n",
      "56   ['jargon', 'animal', 'animal']\n",
      "57   ['routine']\n",
      "58   ['feature', 'factor', 'strip']\n",
      "59   ['developed country', 'universal symbol', 'international award']\n",
      "60   ['song']\n",
      "61   ['cognitive function', 'activity', 'term']\n",
      "62   ['physiological parameter', 'genre']\n",
      "63   ['prop', 'popular war fiction book', 'word']\n",
      "64   []\n",
      "65   ['word', 'ambitious newcomer']\n",
      "66   ['word', 'song', 'factor']\n",
      "67   ['routine']\n",
      "68   []\n",
      "69   ['term', 'expense']\n",
      "70   ['term', 'stakeholder']\n",
      "71   ['neuroprotective strategy', 'factor', 'device']\n",
      "72   ['topic', 'term', 'database exception status']\n",
      "73   ['topic', 'street']\n",
      "74   ['lipid', 'resource']\n",
      "75   ['verb', 'factor', 'family member']\n",
      "76   ['equipment', 'facial expression']\n",
      "77   ['case', 'name']\n",
      "78   ['common ailment', 'aggregate function', 'information']\n",
      "79   ['term', 'field level worker']\n",
      "80   ['category']\n",
      "81   ['food', 'option', 'function']\n",
      "82   ['cruise line', 'celebrity face', 'company']\n",
      "83   ['word']\n",
      "84   []\n",
      "85   ['case', 'name']\n",
      "86   ['protective clothing', 'practice', 'state']\n",
      "87   ['specie', 'currency']\n",
      "88   ['currency', 'activity', 'word']\n",
      "89   ['place', 'modifier']\n",
      "error\n",
      "90   ['plant']\n",
      "91   ['department', 'technique']\n",
      "92   ['medium frame auto handgun']\n",
      "93   ['curricular information', 'user', 'person']\n",
      "94   ['desktop', 'company', 'calendar view']\n",
      "95   ['organisation', 'information']\n",
      "96   ['word', 'factor', 'term']\n",
      "97   ['factor', 'study', 'parameter']\n",
      "98   ['city', 'team', 'word']\n",
      "99   ['attraction', 'artist', 'violent or abusive behavior']\n",
      "100   ['problem', 'cut', 'publication']\n",
      "101   ['christmas related item', 'holiday']\n",
      "102   ['equipment', 'issue', 'term']\n",
      "103   ['person']\n",
      "104   ['skill', 'factor']\n",
      "105   ['habitat', 'road', 'word']\n",
      "106   ['feature', 'brand']\n",
      "107   ['chaperone', 'term', 'circuit']\n",
      "108   ['simple piece']\n",
      "109   ['band', 'market', 'feature']\n",
      "error\n",
      "110   ['concept', 'style name']\n",
      "111   ['japanese boy band', 'breeding program', 'action']\n",
      "112   ['event', 'mattel doll', 'artist']\n",
      "113   ['artist', 'work']\n",
      "114   ['traditional cymbal', 'vehicle', 'specie']\n",
      "115   ['site', 'isg']\n",
      "116   ['asset', 'american girl book']\n",
      "117   ['information', 'information', 'abbreviation']\n",
      "118   ['calendar view', 'term', 'organ']\n",
      "119   ['item', 'accurate transaction', 'word']\n",
      "120   ['technique', 'romantic comedy']\n",
      "121   ['animal', 'india focused terror group', 'film']\n",
      "122   ['category', 'mode']\n",
      "123   ['feeling', 'market dynamic', 'metal']\n",
      "124   ['personality disorder', 'family member']\n",
      "125   ['sample parameter', 'unnecessary word', 'word']\n",
      "126   ['character']\n",
      "127   ['position', 'artist', 'name']\n",
      "128   ['complication', 'skill', 'magical item']\n",
      "129   ['professional development strategy', 'condition', 'topic']\n",
      "130   ['hardware', 'element', 'information']\n",
      "131   ['word', 'accessory', 'accessory']\n",
      "132   ['formal action', 'factor', 'professional development strategy']\n",
      "133   ['activity', 'system action']\n",
      "134   ['factor', 'standard feature', 'long lived asset']\n",
      "error\n",
      "135   ['word']\n",
      "136   ['topic', 'vital sign', 'critical area']\n",
      "137   ['descriptive term', 'researcher']\n",
      "138   ['family member', 'item', 'scheduling policy']\n",
      "139   ['information']\n",
      "140   ['event']\n",
      "141   ['quality', 'field', 'term']\n",
      "142   ['word', 'word']\n",
      "143   ['band', 'professional driver', 'company']\n",
      "144   ['game', 'language', 'issue']\n",
      "145   ['medium', 'social medium']\n",
      "146   ['phrase', 'word', 'lexical filler']\n",
      "147   ['facility', 'hazardous area', 'asset']\n",
      "148   ['nickname']\n",
      "149   ['genre']\n",
      "150   ['team', 'word']\n",
      "151   ['phrase', 'city']\n",
      "152   []\n",
      "153   ['inference', 'term']\n",
      "154   ['brand']\n",
      "155   ['surname', 'person', 'functionality']\n",
      "156   ['sect', 'item', 'style name']\n",
      "157   ['abbreviation', 'classic', 'word']\n",
      "158   ['area']\n",
      "159   ['company', 'abbreviation']\n",
      "160   ['information', 'nationality']\n",
      "161   ['word', 'technical term']\n",
      "162   ['flaw', 'renewable energy policy', 'city']\n",
      "163   ['term', 'cancer treatment']\n",
      "164   ['accessory', 'factor']\n",
      "165   ['factor', 'skill', 'style name']\n",
      "166   ['moisture absorbent material', 'convention', 'tool']\n",
      "167   ['acronym named stock apps', 'word', 'mode']\n",
      "168   ['typical holiday activity']\n",
      "169   ['item', 'interjection', 'feature']\n",
      "170   ['microcontroller', 'team', 'item']\n",
      "171   ['game', 'qualifier', 'institution']\n",
      "172   ['sound', 'word']\n",
      "173   ['company', 'pronoun', 'topic']\n",
      "174   ['topic', 'natural disaster', 'sort option']\n",
      "175   ['datum', 'usable and musical innovation', 'area']\n",
      "176   ['horse', 'word']\n",
      "177   ['directed energy attack', 'plant']\n",
      "178   ['dwarf god']\n",
      "179   ['team', 'word', 'word']\n",
      "180   ['brand', 'advantage']\n",
      "181   ['sin', 'building']\n",
      "182   ['title', 'emotion']\n",
      "183   ['writer', 'company']\n",
      "184   ['term', 'movie', 'necessity']\n",
      "185   ['word']\n",
      "186   ['condition', 'offense', 'aberration']\n",
      "187   ['parameter', 'property']\n",
      "188   ['resource', 'traditional cymbal']\n",
      "error\n",
      "189   ['word']\n",
      "190   ['city', 'program']\n",
      "191   ['musical concept', 'weak verb', 'emotion']\n",
      "192   ['issue', 'currency']\n",
      "193   ['rare earth element', 'leading player', 'algorithm']\n",
      "194   ['word', 'feature', 'factor']\n",
      "195   ['pigmentary property', 'program']\n",
      "196   ['state', 'entirely unsourced, subjective characteristic', 'program']\n",
      "197   ['word']\n",
      "198   ['area']\n",
      "199   ['term', 'body part']\n",
      "200   ['preference']\n",
      "201   ['athlete']\n",
      "202   ['author']\n",
      "203   ['livebearer', 'emotion']\n",
      "204   ['graphic', 'parameter']\n",
      "205   ['chaperone', 'information']\n",
      "206   ['metal lead frame', 'customer', 'word']\n",
      "207   ['product', 'transaction']\n",
      "208   ['word', 'inference']\n",
      "209   ['issue']\n",
      "210   ['item', 'basic command', 'equipment']\n",
      "211   ['machine condition', 'event']\n",
      "212   ['information']\n",
      "213   ['game', 'qualifier']\n",
      "214   ['word', 'area', 'emotion']\n",
      "215   []\n",
      "216   ['activity']\n",
      "217   ['neurodegenerative disease', 'model', 'term']\n",
      "218   ['problem instances', 'character', 'word']\n",
      "219   ['factor', 'personal weapon', 'word']\n",
      "220   ['factor', 'practice', 'relative']\n",
      "221   ['animal', 'style name', 'word']\n",
      "222   ['factor', 'organ']\n",
      "223   ['song', 'pre modifiers']\n",
      "224   ['complication']\n",
      "225   ['video format']\n",
      "226   ['video format']\n",
      "227   ['conservative treatment', 'benefit program', 'word']\n",
      "228   ['word', 'city']\n",
      "229   ['event', 'close contact']\n",
      "230   ['reference word', 'tell tale sign', 'term']\n",
      "231   ['comprehensive function', 'factor']\n",
      "232   ['group', 'word', 'heat generating part']\n",
      "233   ['song', 'term', 'term']\n",
      "234   ['tissue', 'chapter', 'protective clothing']\n",
      "235   ['sector', 'information']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236   ['behaviour state', 'trauma', 'word']\n",
      "237   ['position', 'word']\n",
      "238   ['event']\n",
      "239   ['lesion', 'unit']\n",
      "240   ['verb tense']\n",
      "241   ['word', 'city']\n",
      "242   ['event', 'accident']\n",
      "243   ['student financial aid plan']\n",
      "244   ['guestfish command', 'vague response', 'magazine']\n",
      "245   ['meal', 'established pks', 'feature']\n",
      "246   ['activity', 'student financial aid plan', 'construction option']\n",
      "247   ['factor', 'event', 'game']\n",
      "248   ['portland institution', 'word']\n",
      "249   ['film', 'heat generating part', 'word']\n",
      "250   ['construction option', 'meal', 'issue']\n",
      "251   ['activity', 'place', 'developed country']\n",
      "252   ['cruise missile', 'cookie']\n",
      "253   ['taste deterrent', 'effect', 'neurodegenerative disease']\n",
      "254   ['feature', 'skill', 'superlative']\n",
      "255   []\n",
      "256   ['factor', 'area', 'action']\n",
      "257   ['conversational grunt', 'gas']\n",
      "258   ['structure', 'inflammatory marker', 'calendar view']\n",
      "259   ['activity']\n",
      "260   ['factor', 'transportation equipment']\n",
      "261   ['diet', 'character', 'pre modifiers']\n",
      "262   []\n",
      "263   ['family member']\n",
      "264   ['skill']\n",
      "265   ['factor', 'area', 'action']\n",
      "266   ['word', 'label', 'word']\n",
      "267   ['unsolicited original creative material']\n",
      "268   ['user feature', 'information']\n",
      "269   ['popular attraction', 'issue']\n",
      "270   ['website', 'work', 'city']\n",
      "271   ['city', 'factor']\n",
      "272   ['person', 'key site', 'publication']\n",
      "273   ['material', 'hair', 'keyword']\n",
      "274   ['item']\n",
      "275   ['artist', 'area', 'game']\n",
      "276   ['pigmentary property', 'factor']\n",
      "277   ['state', 'factor']\n",
      "278   ['concept', 'feature', 'unsolicited original creative material']\n",
      "279   ['technique']\n",
      "280   ['game']\n",
      "281   ['item', 'product']\n",
      "282   ['animal', 'secondary effect']\n",
      "283   ['exercise', 'area']\n",
      "284   ['term', 'factor']\n",
      "285   ['rehabilitation diagnosis', 'organ']\n",
      "286   ['word', 'device', 'animal']\n",
      "287   ['assessment', 'first responder', 'event']\n",
      "288   ['chaperone', 'information']\n",
      "289   ['specialist', 'interest']\n",
      "290   ['language', 'offshoot', 'attachment assembly']\n",
      "291   ['item', 'song']\n",
      "error\n",
      "292   ['event']\n",
      "293   ['word', 'behavior', 'accessory']\n",
      "294   ['application', 'factor']\n",
      "295   ['word']\n",
      "296   ['impersonal term', 'calendar view']\n",
      "297   ['accessory', 'accessory', 'eligibility criterion']\n",
      "298   ['state', 'systemic infection', 'activity']\n",
      "299   ['complication', 'symptom']\n",
      "300   ['complication']\n",
      "301   ['value']\n",
      "302   ['factor', 'verb']\n",
      "303   ['century historian']\n",
      "304   ['element', 'street address abbreviation', 'vulnerable group']\n",
      "305   ['descriptive statistic', 'factor']\n",
      "306   ['program area', 'consequent fuel']\n",
      "307   ['ptb containing protein']\n",
      "308   []\n",
      "309   ['property']\n",
      "310   []\n",
      "311   ['verb tense', 'word']\n",
      "312   ['factor', 'feature', 'study']\n",
      "313   ['apostle', 'popular memory card']\n",
      "314   ['capability', 'factor']\n",
      "315   ['beach', 'body modification', 'artist']\n",
      "error\n",
      "316   ['word']\n",
      "317   ['place', 'term', 'assessment']\n",
      "318   ['spell', 'character', 'word']\n",
      "319   ['technique', 'word', 'blessing']\n",
      "320   ['narrative keyword search term', 'device']\n",
      "321   ['item', 'abbreviation']\n",
      "322   ['platform company', 'parameter', 'brand']\n",
      "323   ['information', 'operation', 'word']\n",
      "324   ['african country']\n",
      "325   ['researcher', 'heavy metal', 'industry']\n",
      "326   ['group', 'field army', 'directional term']\n",
      "327   ['food', 'herb']\n",
      "328   ['strategy', 'province']\n",
      "329   ['emotion']\n",
      "330   ['title', 'discipline']\n",
      "331   ['name', 'finish', 'functionality']\n",
      "332   ['swimming stroke', 'feature', 'superlative']\n",
      "333   ['name', 'word']\n",
      "334   ['word', 'activity', 'word']\n",
      "335   ['information']\n",
      "336   ['topographical feature', 'factor']\n",
      "337   ['film', 'acronym named stock apps', 'term']\n",
      "338   ['emotion', 'facial expression', 'city']\n",
      "error\n",
      "339   ['organelle']\n",
      "340   ['feature', 'program', 'function']\n",
      "341   ['food']\n",
      "342   ['development task', 'player', 'emotion']\n",
      "343   ['word']\n",
      "344   ['aspect']\n",
      "345   ['document', 'craft store', 'metal']\n",
      "346   ['title', 'function', 'discipline']\n",
      "347   ['area', 'conservative treatment']\n",
      "348   ['medium']\n",
      "349   ['accessory', 'operator', 'limited information']\n",
      "350   ['test']\n",
      "351   ['genre', 'text', 'book']\n",
      "352   ['big hitter', 'issue', 'language']\n",
      "353   ['cancer treatment']\n",
      "354   ['diner', 'character', 'minor people']\n",
      "355   ['technology', 'equipment', 'word']\n",
      "356   ['input device', 'part', 'preference']\n",
      "357   ['word', 'for profit education company', 'group']\n",
      "358   []\n",
      "359   ['word', 'song']\n",
      "360   ['chaperone', 'information']\n",
      "361   ['theme', 'resource']\n",
      "362   ['symptom', 'city']\n",
      "363   ['information']\n",
      "364   ['word', 'rare earth element', 'gas']\n",
      "365   ['province', 'prosocial behavior', 'service']\n",
      "366   ['nba player', 'factor', 'computer']\n",
      "367   ['river', 'ancillary item']\n",
      "368   ['game']\n",
      "369   ['rhyming word']\n",
      "370   ['item', 'soap opera', 'open-source protocol']\n",
      "error\n",
      "371   ['word']\n",
      "372   ['topic', 'popular phrase']\n",
      "373   ['month', 'specie']\n",
      "374   ['firm', 'industry', 'game']\n",
      "375   ['word', 'account']\n",
      "376   ['city', 'work']\n",
      "377   ['factor', 'month']\n",
      "378   ['word', 'factor', 'word']\n",
      "379   ['guestfish command']\n",
      "380   ['factor', 'cosmetic']\n",
      "381   ['concept']\n",
      "382   ['derivative', 'process']\n",
      "383   ['soft cheese', 'film']\n",
      "384   []\n",
      "385   ['option', 'aggregate function', 'activity']\n",
      "386   ['treatment', 'professional', 'word']\n",
      "387   ['sense', 'brand', 'command']\n",
      "388   ['role', 'book', 'word']\n",
      "389   ['character', 'information', 'stat']\n",
      "390   ['naproxen containing product', 'multimedia element']\n",
      "391   ['word', 'factor', 'region']\n",
      "392   ['amenity', 'region', 'keyword']\n",
      "393   ['test', 'resource']\n",
      "394   ['term', 'activity']\n",
      "395   ['word', 'factor']\n",
      "396   []\n",
      "397   ['character', 'exotic and faraway place', 'light color']\n",
      "398   ['topic', 'benefit', 'group']\n",
      "399   ['company']\n",
      "400   ['fanworks', 'superstar']\n",
      "401   ['word', 'substance', 'issue']\n",
      "402   ['interjection', 'middle term', 'shipping option']\n",
      "403   ['administrative duty', 'musical theatre production', 'word']\n",
      "404   []\n",
      "405   ['emotion', 'case']\n",
      "406   ['dwarf god']\n",
      "407   ['note', 'ergonomic factor']\n",
      "408   ['specie', 'word']\n",
      "409   ['rare behavior', 'sport', 'word']\n",
      "410   ['factor', 'deep foundation']\n",
      "411   ['animal', 'livebearer']\n",
      "412   ['term', 'factor', 'term']\n",
      "413   ['information', 'school', 'topic']\n",
      "414   ['technology', 'top player']\n",
      "415   ['factor', 'organ', 'condition']\n",
      "416   ['occasion', 'term', 'factor']\n",
      "417   ['factor', 'word', 'area']\n",
      "418   ['activity', 'apps', 'event']\n",
      "419   ['chaperone', 'information']\n",
      "420   ['compatibility aid', 'scholar']\n",
      "421   ['emotion']\n",
      "422   ['mandatory item']\n",
      "423   ['property', 'step']\n",
      "424   ['element', 'skin condition']\n",
      "425   ['calendar view', 'company', 'professional']\n",
      "426   ['work', 'topic', 'usenet newsreader']\n",
      "427   ['risk factor', 'lipid']\n",
      "428   ['condition', 'word', 'function']\n",
      "429   ['descriptive statistic', 'factor']\n",
      "430   ['food', 'single', 'beverage']\n",
      "431   ['measure', 'feature']\n",
      "432   ['preacher', 'herb']\n",
      "433   ['area', 'author', 'writer']\n",
      "434   ['high speed network interface', 'genre']\n",
      "435   ['facial feature', 'feature', 'dance form']\n",
      "436   ['feature', 'lexical filler', 'information']\n",
      "437   ['date', 'month']\n",
      "438   ['animal', 'feature', 'language']\n",
      "439   ['top publication']\n",
      "440   ['word', 'discipline']\n",
      "441   ['emotion', 'song', 'word']\n",
      "442   ['factor', 'body fluid', 'brand']\n",
      "443   ['industry', 'movie']\n",
      "444   ['standard file format', 'event', 'issue']\n",
      "445   ['datum type', 'vehicle', 'heat generating part']\n",
      "446   ['animal', 'style name', 'word']\n",
      "447   ['factor', 'cosmetic']\n",
      "448   ['slogan']\n",
      "449   ['feature', 'feature']\n",
      "450   ['information', 'vague word']\n",
      "451   ['subject', 'scholar']\n",
      "452   ['brand', 'brand', 'cartoon']\n",
      "453   ['brain region', 'emotion', 'piercing']\n",
      "454   ['function', 'debris', 'activity']\n",
      "455   ['word']\n",
      "456   ['organ', 'publication', 'brand']\n",
      "457   ['action verb', 'woman']\n",
      "458   ['song', 'vendor', 'term']\n",
      "459   ['system component']\n",
      "460   ['step']\n",
      "461   ['three star hotel', 'advantage']\n",
      "462   []\n",
      "463   ['complication', 'severe case', 'inflammation']\n",
      "464   ['calendar view']\n",
      "465   ['matching abbreviation', 'title', 'discipline']\n",
      "466   ['word', 'word']\n",
      "467   ['word', 'breast change']\n",
      "468   ['town']\n",
      "469   ['game show', 'confidence level']\n",
      "470   ['animal', 'style name', 'word']\n",
      "471   ['preference']\n",
      "472   ['item', 'label', 'item']\n",
      "473   ['song']\n",
      "474   ['description', 'lipid']\n",
      "475   ['song', 'ritual duty']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476   ['project', 'word']\n",
      "477   ['item', 'information', 'exception']\n",
      "478   ['word', 'emotion']\n",
      "479   ['emotion', 'tell tale sign', 'factor']\n",
      "480   ['type', 'term']\n",
      "481   ['topic', 'medium file format', 'inner condition']\n",
      "482   ['life threatening heart problem', 'parameter', 'story']\n",
      "483   ['writer', 'city']\n",
      "484   []\n",
      "485   ['common measurement', 'mode', 'movie']\n",
      "486   ['arm dealer', 'expense']\n",
      "487   ['group', 'emboli', 'variable']\n",
      "488   ['image capture mode', 'group', 'emboli']\n",
      "489   ['song']\n",
      "490   ['resource', 'food']\n",
      "491   ['tool']\n",
      "492   ['chaperone', 'information']\n",
      "493   ['occult industry']\n",
      "494   ['item', 'problem', 'cutest small tattoo idea']\n",
      "495   ['city', 'factor', 'gas']\n",
      "error\n",
      "496   ['factor']\n",
      "497   []\n",
      "498   ['huge festival', 'well known brand']\n",
      "499   ['preference', 'laughter', 'writer']\n",
      "500   ['word', 'offense', 'activity']\n",
      "501   ['item']\n",
      "502   ['factor']\n",
      "503   ['term', 'sport']\n",
      "504   ['jargon']\n",
      "505   ['notable song', 'condition']\n",
      "506   ['measure', 'command']\n",
      "507   ['study', 'company', 'document']\n",
      "508   ['extreme flight situation']\n",
      "509   ['word', 'activity', 'sub-systems']\n",
      "510   ['popular handgun caliber', 'term']\n",
      "511   ['calendar view', 'publication', 'character']\n",
      "error\n",
      "512   ['move']\n",
      "513   ['non named role', 'concept']\n",
      "514   ['coupling reaction', 'ldap compliant directory', 'animal']\n",
      "515   ['facial feature', 'province', 'term']\n",
      "516   ['message theme', 'activity']\n",
      "517   ['option', 'network']\n",
      "518   ['word', 'word']\n",
      "519   ['statement', 'hindi film', 'stakeholder']\n",
      "520   ['program', 'factor']\n",
      "521   ['rhyming word']\n",
      "522   ['email address', 'asset']\n",
      "523   ['game', 'term', 'song']\n",
      "524   ['sexual problem', 'method', 'factor']\n",
      "525   ['name', 'qualification']\n",
      "526   ['word']\n",
      "527   ['subject area', 'phrase', 'practice']\n",
      "528   ['leading brand name', 'area']\n",
      "529   ['item', 'gene']\n",
      "530   ['food', 'utilising different talent search method', 'commentator']\n",
      "531   ['document', 'adjective']\n",
      "532   ['factor', 'sense', 'object']\n",
      "533   ['song', 'facial hair', 'group']\n",
      "534   ['condition', 'nonsteroidal anti inflammatory drug']\n",
      "535   ['item', 'option', 'metal']\n",
      "536   ['item', 'multi author site']\n",
      "537   ['population', 'vulnerable group']\n",
      "538   []\n",
      "539   ['verb', 'word']\n",
      "540   ['festival', 'european country', 'concept']\n",
      "541   ['season', 'scheduling policy']\n",
      "542   ['issue']\n",
      "543   ['yearly event', 'factor']\n",
      "544   ['factor']\n",
      "545   ['factor', 'parameter', 'body fluid']\n",
      "546   ['adverb', 'factor', 'term']\n",
      "547   ['abbreviation', 'phrase', 'word']\n",
      "548   ['symptom']\n",
      "549   ['microcontroller', 'term structure model', 'feature']\n",
      "550   ['item', 'network device']\n",
      "551   ['chaperone', 'month']\n",
      "552   ['regenerative indication', 'machine']\n",
      "553   ['name merges', 'information', 'hybrid language']\n",
      "554   ['user']\n",
      "555   ['topic', 'professional']\n",
      "556   ['river', 'stock character']\n",
      "557   ['feeling', 'company']\n",
      "558   ['title', 'discipline']\n",
      "559   []\n",
      "560   ['concept']\n",
      "561   ['item', 'multi author site']\n",
      "562   ['service', 'word']\n",
      "563   ['song', 'satan s music']\n",
      "564   ['person', 'factor', 'word']\n",
      "565   ['comfortable clothing', 'trauma', 'factor']\n",
      "566   ['term', 'contender', 'button']\n",
      "567   ['organ', 'sense']\n",
      "568   ['number']\n",
      "569   ['factor', 'ethnicity']\n",
      "570   ['location', 'option', 'vulnerable group']\n",
      "571   ['benefit']\n",
      "572   ['function', 'component', 'rating agency']\n",
      "573   ['factor', 'state', 'metabolic condition']\n",
      "574   ['grammatical category']\n",
      "575   ['activity', 'word']\n",
      "576   ['extension', 'information']\n",
      "577   ['defence', 'hdac inhibitor']\n",
      "578   ['act', 'room type', 'information']\n",
      "579   ['factor', 'term']\n",
      "580   ['possibility', 'item', 'calendar view']\n",
      "581   ['activity', 'message theme']\n",
      "582   ['information', 'shape', 'utterance']\n",
      "583   ['body part', 'city']\n",
      "584   ['factor']\n",
      "585   ['verb', 'operator']\n",
      "586   ['capitalize word', 'activity', 'time']\n",
      "587   ['word', 'item']\n",
      "588   ['certification', 'issue']\n",
      "589   ['agency', 'investor', 'author']\n",
      "590   ['advanced test', 'organism', 'field prop']\n",
      "591   ['legendary tv sitcom', 'medium']\n",
      "592   ['feature']\n",
      "593   ['program']\n",
      "594   ['spell', 'design pattern', 'word']\n",
      "595   ['information']\n",
      "596   ['title', 'researcher', 'interviewee']\n",
      "597   ['operation']\n",
      "598   ['forward looking statement', 'factor']\n",
      "599   ['information', 'information']\n",
      "600   ['item', 'material', 'person']\n",
      "601   ['property', 'word']\n",
      "602   ['spell', 'material']\n",
      "603   ['indefinite pronoun', 'organization', 'fun award']\n",
      "604   ['gartley pattern', 'resource', 'network']\n",
      "605   ['word', 'great feature']\n",
      "606   ['family member', 'event']\n",
      "607   ['exercise', 'word', 'word']\n",
      "608   ['weak verb', 'emotion']\n",
      "609   ['film', 'word', 'oil based product']\n",
      "610   ['gene', 'asset']\n",
      "611   ['dramatic expressive word', 'software', 'information']\n",
      "612   ['term', 'organization', 'prophet']\n",
      "613   ['event', 'asset']\n",
      "614   ['key']\n",
      "615   ['measure']\n",
      "616   ['word', 'factor']\n",
      "617   ['study']\n",
      "618   ['area', 'factor']\n",
      "619   ['factor', 'vrs', 'device']\n",
      "620   ['slang word', 'factor', 'affective term']\n",
      "621   ['group']\n",
      "622   ['item', 'material', 'person']\n",
      "623   ['technology', 'word']\n",
      "624   ['word', 'entropy', 'factor']\n",
      "625   ['study', 'teacher resource']\n",
      "626   ['study', 'outfit']\n",
      "627   ['chaperone', 'information']\n",
      "error\n",
      "628   ['concept', 'style name']\n",
      "629   ['item', 'source']\n",
      "630   ['vulcanization system']\n",
      "631   ['event', 'acronym']\n",
      "632   ['part of an expression', 'ingredient']\n",
      "633   ['concept', 'game']\n",
      "634   ['character', 'information']\n",
      "635   ['situation', 'information']\n",
      "636   ['feature', 'area', 'easy scarf']\n",
      "637   ['parameter', 'concept']\n",
      "638   ['parameter', 'prefix', 'party']\n",
      "639   ['time', 'emergency vehicle', 'organelle']\n",
      "640   ['film', 'method', 'prefix']\n",
      "641   ['benefit', 'single word', 'facial feature']\n",
      "642   ['solution', 'reactive monomer', 'mode of payment']\n",
      "643   ['substance', 'activity']\n",
      "644   ['word', 'term', 'factor']\n",
      "645   ['fish', 'great leader', 'amino acid']\n",
      "646   ['class', 'factor']\n",
      "647   ['national australian pop tv show']\n",
      "648   ['city', 'natural disaster']\n",
      "649   ['item', 'standard ftp operation']\n",
      "650   ['term', 'activity']\n",
      "651   ['group']\n",
      "652   ['term', 'item']\n",
      "653   ['technique', 'information']\n",
      "654   ['song']\n",
      "655   ['protection', 'non committal word']\n",
      "656   ['attachment', 'character']\n",
      "657   ['program']\n",
      "658   ['skill', 'court proceeding']\n",
      "659   ['city', 'cable']\n",
      "660   ['criterion', 'city', 'dark color']\n",
      "661   ['factor', 'factor']\n",
      "662   ['animal', 'state']\n",
      "663   ['object', 'word']\n",
      "664   ['optical constant', 'acronym named stock apps', 'benefit program']\n",
      "665   ['factor']\n",
      "666   ['information', 'diver material']\n",
      "667   ['beverage', 'term', 'purpose']\n",
      "668   []\n",
      "669   ['term', 'grade', 'word']\n",
      "670   ['factor']\n",
      "671   ['option']\n",
      "672   ['relative']\n",
      "673   ['verb tense', 'operation']\n",
      "674   ['occasion card', 'liquid']\n",
      "675   ['emotion']\n",
      "676   ['activity', 'sport']\n",
      "677   ['slang word', 'oil company', 'mechanism']\n",
      "678   ['information', 'technology']\n",
      "679   ['message theme']\n",
      "680   ['filler word', 'band']\n",
      "681   ['test', 'word', 'role']\n",
      "682   ['target', 'calendar view']\n",
      "683   ['established bbc scheme', 'band']\n",
      "684   ['character', 'style name', 'animal']\n",
      "685   ['high profile project']\n",
      "686   ['service']\n",
      "687   ['term']\n",
      "688   ['technology', 'alien machine']\n",
      "689   ['natural phenomenon', 'term', 'time']\n",
      "690   ['narrative keyword search term']\n",
      "691   ['author', 'person', 'topic']\n",
      "692   ['factor', 'term']\n",
      "693   ['name', 'complication', 'inflammation']\n",
      "694   ['suffix', 'channel', 'area']\n",
      "695   ['relative unit']\n",
      "696   ['topic', 'word', 'concept']\n",
      "697   ['film', 'title', 'fabric']\n",
      "698   ['language', 'interjection', 'word']\n",
      "699   ['personal information', 'bleeding', 'complication']\n",
      "700   ['keyword', 'sexual accessory', 'function']\n",
      "701   ['factor', 'journal', 'information']\n",
      "702   ['factor']\n",
      "703   ['control scheme', 'insurance term']\n",
      "704   ['group', 'organization', 'concept']\n",
      "705   ['term', 'activity']\n",
      "706   ['word', 'room', 'hardware']\n",
      "707   ['extremity', 'utterance', 'factor']\n",
      "708   ['word', 'contraction']\n",
      "709   ['organ', 'lipoprotein']\n",
      "710   ['active word', 'factor', 'word']\n",
      "711   ['factor', 'activity', 'factor']\n",
      "error\n",
      "712   []\n",
      "713   ['factor', 'information', 'role']\n",
      "714   ['facial hair', 'feature']\n",
      "715   []\n",
      "716   ['word', 'term']\n",
      "717   ['film', 'company', 'amenity']\n",
      "718   ['movie', 'word', 'title']\n",
      "719   ['item']\n",
      "720   ['factor', 'factor', 'symptom']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721   ['short hand', 'example word']\n",
      "722   ['family member']\n",
      "723   ['vehicle', 'information']\n",
      "724   ['effect', 'test']\n",
      "725   ['item', 'baked good']\n",
      "726   ['title', 'song']\n",
      "727   []\n",
      "728   ['battle', 'standardized test', 'information']\n",
      "729   ['area', 'behaviour state']\n",
      "730   ['area']\n",
      "731   ['word', 'feature']\n",
      "732   ['men s magazine', 'organization', 'factor']\n",
      "733   ['way', 'single incident', 'meat']\n",
      "734   ['cheap sunglasse']\n",
      "735   ['object', 'item']\n",
      "736   ['quality equestrian facility', 'event', 'occasion']\n",
      "737   ['city', 'pre defined label']\n",
      "738   ['county']\n",
      "739   ['specie', 'resource']\n",
      "740   ['information', 'factor']\n",
      "741   ['song', 'modern facility', 'producer']\n",
      "742   ['factor', 'rim']\n",
      "743   []\n",
      "744   ['person']\n",
      "745   ['demographic information', 'resource', 'diversity library']\n",
      "746   ['information', 'social medium', 'qualifier']\n",
      "747   ['prenatal screening test', 'item', 'artificial sweetener']\n",
      "748   ['glacial theorist', 'study']\n",
      "749   ['damage', 'brand', 'area']\n",
      "750   ['title', 'discipline']\n",
      "751   ['word', 'organization']\n",
      "752   ['character', 'word']\n",
      "753   ['livebearer', 'medium']\n",
      "754   ['family based immigration service', 'nonwords']\n",
      "755   ['plugins', 'classical onconeuronal antibody', 'term']\n",
      "756   ['word', 'image format']\n",
      "757   ['fun award', 'object', 'reagent']\n",
      "758   ['factor', 'profession', 'local government']\n",
      "759   ['structural feature', 'negative accountability', 'subclasses']\n",
      "760   ['river', 'engine', 'intangible asset']\n",
      "761   ['word', 'institution']\n",
      "762   ['field', 'minor film']\n",
      "763   ['interpersonal verb', 'term']\n",
      "764   ['top brand', 'content word', 'person']\n",
      "765   ['insect', 'dairy product', 'bland food']\n",
      "766   ['institution']\n",
      "767   ['protein', 'response']\n",
      "768   ['diver material', 'topic']\n",
      "769   ['magazine', 'factor', 'school']\n",
      "770   ['fun belt buckle theme', 'style']\n",
      "771   ['variable']\n",
      "772   ['state', 'adhesive', 'city']\n",
      "773   ['good oral hygiene', 'item', 'instruction']\n",
      "774   ['word']\n",
      "775   ['application', 'personality disorder', 'concept']\n",
      "776   ['band', 'metric', 'factor']\n",
      "777   ['word', 'factor']\n",
      "778   ['information', 'factor']\n",
      "779   ['service', 'word']\n",
      "780   ['food', 'food']\n",
      "781   ['device', 'marine mammal', 'title']\n",
      "782   ['city', 'area']\n",
      "783   ['topic', 'service', 'factor']\n",
      "784   ['ethnic group', 'problem']\n",
      "785   ['player', 'long person', 'city']\n",
      "786   ['sense', 'animal']\n",
      "787   ['word']\n",
      "788   ['word']\n",
      "789   ['county', 'document']\n",
      "790   ['subplot', 'small animal', 'india focused terror group']\n",
      "791   ['language']\n",
      "792   ['issue', 'making film']\n",
      "793   ['station', 'approximate time', 'setting']\n",
      "794   ['word', 'bird', 'study']\n",
      "795   ['name']\n",
      "796   ['information', 'unit', 'derogatory term']\n",
      "797   ['museum', 'song', 'musical']\n",
      "798   ['jewish socialist', 'specialty hospital']\n",
      "799   ['equipment', 'behavior']\n",
      "800   ['task', 'defect']\n",
      "801   ['issue', 'defect']\n",
      "802   ['term']\n",
      "803   ['flower', 'author', 'area']\n",
      "804   ['word', 'credit card']\n",
      "805   ['factor']\n",
      "806   ['process', 'setting', 'action']\n",
      "807   ['arab country', 'professional', 'vague term']\n",
      "808   ['unit']\n",
      "809   ['red icon', 'county']\n",
      "810   ['shape', 'non economic damage']\n",
      "811   ['word', 'word']\n",
      "812   ['muscle dude', 'researcher']\n",
      "813   ['term', 'word', 'factor']\n",
      "814   ['ignition source', 'assignment', 'topic']\n",
      "815   ['word', 'word']\n",
      "816   ['edible medium', 'datum structure']\n",
      "817   ['term', 'word', 'factor']\n",
      "818   ['item', 'process']\n",
      "819   ['modality', 'activity']\n",
      "820   ['factor', 'cognitive function', 'information']\n",
      "821   ['activity']\n",
      "822   ['factor', 'symptom', 'health care system']\n",
      "823   ['information', 'advanced exercise', 'resource']\n",
      "824   ['experience', 'item', 'factor']\n",
      "825   ['order management system', 'teleost fish', 'word']\n",
      "826   ['word', 'factor']\n",
      "827   ['company', 'royal mail service', 'part']\n",
      "828   ['word', 'information', 'athlete']\n",
      "829   ['item']\n",
      "830   ['activity', 'key scrum ceremony']\n",
      "831   ['datum', 'revenue', 'brand']\n",
      "832   ['character', 'information', 'word']\n",
      "833   ['film', 'vulnerable group', 'symptom']\n",
      "834   ['vague predicate', 'activity']\n",
      "835   ['change', 'substance', 'word']\n",
      "836   ['american girl book', 'factor', 'word']\n",
      "837   ['programming', 'service', 'role']\n",
      "838   ['advertisingoriented website', 'status', 'institution']\n",
      "839   ['activity', 'reagent']\n",
      "840   ['event']\n",
      "841   ['recording', 'database object']\n",
      "842   ['issue', 'simple piece']\n",
      "843   ['event', 'sort option']\n",
      "844   ['town', 'commercial item', 'scheduling policy']\n",
      "845   ['time', 'tell tale sign']\n",
      "846   ['serious adverse event']\n",
      "847   ['film', 'word', 'audio filter']\n",
      "error\n",
      "848   ['skill']\n",
      "849   ['term', 'election', 'facial feature']\n",
      "850   ['agent', 'material', 'athlete']\n",
      "851   ['word', 'object']\n",
      "852   ['activity', 'item']\n",
      "853   ['kresal-related evergreen', 'subject']\n",
      "854   ['aspect', 'element']\n",
      "855   ['action words', 'phytohormone']\n",
      "856   ['specie']\n",
      "857   ['complex hydrogeologic condition', 'flat bone']\n",
      "858   ['factor', 'abbreviation', 'device specific information']\n",
      "859   ['information', 'time sensitive information', 'benefit']\n",
      "860   ['information']\n",
      "861   ['company', 'element', 'minor film']\n",
      "862   ['sport', 'hydrologist', 'manufacturer']\n",
      "863   ['long period', 'debuff', 'domain']\n",
      "864   ['researcher', 'oil company']\n",
      "865   ['instrument', 'disturbance']\n",
      "866   ['biomarker', 'vehicle']\n",
      "867   ['content', 'professional']\n",
      "868   ['event', 'verb', 'title']\n",
      "869   ['symptom', 'term']\n",
      "870   ['area', 'person']\n",
      "871   ['exercise', 'oil based product']\n",
      "872   ['mutation', 'night', 'person']\n",
      "873   []\n",
      "874   ['word', 'season']\n",
      "875   ['medium', 'verb']\n",
      "876   ['finish']\n",
      "877   ['document', 'topic']\n",
      "878   ['feature', 'student', 'item']\n",
      "879   ['complex medium', 'word']\n",
      "880   ['successful person', 'concept']\n",
      "881   ['component']\n",
      "882   ['season']\n",
      "883   ['word']\n",
      "884   ['fluid', 'study', 'concept']\n",
      "885   ['fruit']\n",
      "886   ['organ', 'term']\n",
      "887   ['statistic', 'connector type']\n",
      "888   ['activity', 'organ', 'word']\n",
      "889   ['topic']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# pay attention the tfidf vector it's only for df_stroke\n",
    "X = vectorizer.fit_transform(df_stroke.tweet.tolist())\n",
    "# print(vectorizer.get_feature_names()[2042])\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())\n",
    "\n",
    "# edit the max_weight_word_num to set the number of words for extracting concepts\n",
    "max_weight_word_num=1\n",
    "df_concepts={}\n",
    "\n",
    "# look at the top words\n",
    "for index, rows in df.iterrows(): \n",
    "    doc_emb=rows.values\n",
    "    max_tfidf_inds=np.array(doc_emb.argsort()[-3:][::-1])\n",
    "#     print(doc_emb[max_tfidf_inds])\n",
    "    df_concepts[index]=[]\n",
    "    for n,ind in enumerate(max_tfidf_inds):\n",
    "#         print(vectorizer.get_feature_names()[ind])\n",
    "        con=get_concepts(vectorizer.get_feature_names()[ind])\n",
    "#         print(con)\n",
    "        if(con!=[]):\n",
    "            df_concepts[index].append(con[0])\n",
    "#         else:\n",
    "#             df_concepts[index].append([])\n",
    "            \n",
    "    print(index,' ',df_concepts[index])\n",
    "#     if(index+1==11):\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_dic=df_concepts.copy()\n",
    "fpath='../clean_data/PHM2017/concepts.txt'\n",
    "\n",
    "# with open(fpath,'w') as f:\n",
    "#     f.write(str(copy_dic))\n",
    "with open(fpath,'r') as f:\n",
    "    id_map_concept=eval(f.read())\n",
    "# pprint(id_map_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_embed=np.array(np.zeros((len(id_map_concept.keys()),EMBEDDING_DIM)))\n",
    "concept_embed.shape\n",
    "for ind in id_map_concept:\n",
    "    if(id_map_concept[ind]==[]):\n",
    "        continue\n",
    "    else:\n",
    "#         only take the first concept to do evaluation\n",
    "        cur_con=id_map_concept[ind][0]\n",
    "#         print(cur_con)\n",
    "        l=len(cur_con.split())\n",
    "        each_con_emb=np.zeros((1,EMBEDDING_DIM))\n",
    "        if(l>1):# if a concept has many words\n",
    "#             average embedding of words to form concept embedding\n",
    "            all_w_emb=np.zeros((l,EMBEDDING_DIM))\n",
    "            for j,w in enumerate(cur_con.split()):\n",
    "#                 print(j,w)\n",
    "                if(w in embedding_dic):\n",
    "                    all_w_emb[j]=embedding_dic[w]\n",
    "            each_con_emb=np.mean(all_w_emb,axis=0)\n",
    "        elif(l==1):\n",
    "            if(cur_con in embedding_dic):\n",
    "                each_con_emb=embedding_dic[cur_con]\n",
    "        concept_embed[ind]=each_con_emb\n",
    "        \n",
    "            \n",
    "# embedding_dic[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_emb=np.zeros((len(dataset),EMBEDDING_DIM))\n",
    "for i in range(len(dataset)):\n",
    "    each_emb=np.zeros((len(dataset[i]),EMBEDDING_DIM))\n",
    "    for j,w in enumerate(dataset[i]):\n",
    "        if(w in embedding_dic):\n",
    "            each_emb[j]=embedding_dic[w]\n",
    "#             break\n",
    "    data_emb[i]=np.mean(each_emb, axis=0)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890, 300)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890, 300)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890, 600)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_emb=np.concatenate((data_emb,concept_embed),axis=1)\n",
    "concat_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([26.37706256, 12.96767926, 27.38781023, 25.32210255, 23.16729307]),\n",
       " 'score_time': array([0.00897717, 0.00997305, 0.00901079, 0.01099658, 0.0129652 ]),\n",
       " 'test_precision_macro': array([0.4402598 , 0.49587081, 0.50674505, 0.5420612 , 0.4912663 ]),\n",
       " 'train_precision_macro': array([1.        , 1.        , 0.99766355, 1.        , 0.99022005]),\n",
       " 'test_recall_macro': array([0.43563817, 0.4634062 , 0.50809063, 0.51983933, 0.37363041]),\n",
       " 'train_recall_macro': array([1.        , 1.        , 0.99872774, 1.        , 0.97787259]),\n",
       " 'test_f1_macro': array([0.43735219, 0.47337291, 0.50692519, 0.52929244, 0.38360035]),\n",
       " 'train_f1_macro': array([1.        , 1.        , 0.99818854, 1.        , 0.98363497])}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "hidden_neurons=600\n",
    "    \n",
    "classifier = MLPClassifier(hidden_layer_sizes=(hidden_neurons), max_iter=1000, alpha=0.03,\n",
    "                     solver='adam', verbose=0,  random_state=0)\n",
    "\n",
    "print(\"start training..\")\n",
    "# classifier.fit(X_train_emb,y_train)\n",
    "scoring = ['precision_macro', 'recall_macro','f1_macro']\n",
    "scores = cross_validate(classifier, concat_emb, df_stroke.label, \n",
    "#                         print evaluation metric for each class\n",
    "#                          scoring=make_scorer(classification_report_with_accuracy_score),\n",
    "                         scoring=scoring,\n",
    "                         cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some thoughts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning some params of nerual network, it seems directly input the embedding of concept information actually **worsen the result** to an extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some thoughts:\n",
    "- maybe the words chosen by tfidf weight is not applicable in this task?\n",
    "- the experiment only include top1 concept, maybe include more information about concepts?\n",
    "- any better way we can measure the whole tweet and get better knowledge?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline results for all classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alzheimer=df[df['symptom']=='alzheimer'][['tweet','label']]\n",
    "df_cancer=df[df['symptom']=='cancer'][['tweet','label']]\n",
    "df_depression=df[df['symptom']=='depression'][['tweet','label']]\n",
    "df_heart_attack=df[df['symptom']=='heart attack'][['tweet','label']]\n",
    "df_parkinson=df[df['symptom']=='parkinson'][['tweet','label']]\n",
    "df_stroke=df[df['symptom']=='stroke'][['tweet','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.865px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
